reward_func,violation_penalty_scl,debug_log_prob,decay_steps,model_dir,rmsprop_epsil,clip_norm,h_regu_frac,rwd_e_para,test_env,is_warm_start,train_act_func,action_repeat_n,output,state_dim,isNoisyNetEval_rmNoise,end_e,eval_act_func,sharedNet_type,train_freq,num_threads,save_scope,forecast_dim,learning_rate,init_e,v_loss_frac,learning_rate_decay_rate,metric_func,save_freq,job_mode,eval_freq,action_space,isNoisyNet,weight_initer,activation,learning_rate_decay_steps,test_mode,agent_num,max_interactions,rmsprop_decay,p_loss_frac,rmsprop_momet,is_greedy_policy,rwd_p_para,is_learning_rate_decay_staircase,model_param,check_args_only,eval_epi_num,raw_state_prcs_func,save_max_to_keep,h_decay_bounds,model_type,gamma,env,dropout_prob,window_len
cslDxCool_1,10.0,0.0005,1000000,None,1e-10,5.0,[0.0],1.0,Model1-Test-Cool-v1,False,cslDxActCool_1,1,a3c-res-v0.1,49,True,0.0,cslDxActCool_1,Dense,5,16,all,0,0.001,0.0,0.5,0.9,cslDxCool_1,500000,Train,250000,cslDxCool_1,True,glorot_uniform,relu,100000,Multiple,5,5000000,0.99,1.0,0.0,False,1.0,False,"[512, 2]",True,1,cslDx_1,5,[],nn,0.99,Model1-Cool-v1,0.0,6
