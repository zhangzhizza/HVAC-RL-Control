reward_func,decay_steps,rmsprop_momet,env,is_greedy_policy,isNoisyNet,h_regu_frac,window_len,eval_act_func,raw_state_prcs_func,rmsprop_decay,sharedNet_type,clip_norm,metric_func,test_mode,activation,learning_rate_decay_steps,isNoisyNetEval_rmNoise,save_scope,learning_rate_decay_rate,model_dir,dropout_prob,agent_num,train_act_func,forecast_dim,train_freq,check_args_only,model_param,save_freq,h_decay_bounds,eval_freq,job_mode,state_dim,gamma,violation_penalty_scl,action_space,init_e,max_interactions,learning_rate,debug_log_prob,test_env,action_repeat_n,save_max_to_keep,rwd_p_para,num_threads,p_loss_frac,rmsprop_epsil,model_type,output,rwd_e_para,v_loss_frac,weight_initer,eval_epi_num,end_e,is_warm_start,is_learning_rate_decay_staircase
cslDxCool_1,1000000,0.0,Model1-Cool-v1,False,False,[0.1],6,cslDxActCool_1,cslDx_1,0.99,Dense,5.0,cslDxCool_1,Multiple,tanh/relu,100000,False,all,0.9,None,0.0,5,cslDxActCool_1,0,5,True,"[8, 4, 8, 4]",500000,[],250000,Train,49,0.99,10.0,cslDxCool_1,0.0,10000000,0.001,0.0005,Model1-Test-Cool-v1,1,5,1.0,16,1.0,1e-10,lstm,a3c-res-v0.1,1.0,0.5,glorot_uniform,1,0.0,False,False
